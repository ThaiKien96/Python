{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from os import listdir\n",
    "%matplotlib inline  \n",
    "\n",
    "SZ = 32\n",
    "SIZE = 32\n",
    "CLASS_N = 9\n",
    "CLASS_NUMBER = 9\n",
    "# local modules\n",
    "from common import clock, mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_traffic_dataset():\n",
    "    dataset = []\n",
    "    labels = []\n",
    "    for sign_type in range(CLASS_NUMBER):\n",
    "        sign_list = listdir(\"./source/Training/data/{}\".format(sign_type))\n",
    "        for sign_file in sign_list:\n",
    "            path = \"./source/Training/data/{}/{}\".format(sign_type,sign_file)\n",
    "            img = cv2.imread(path,0)\n",
    "            img = cv2.resize(img, (32,32))\n",
    "            img = np.reshape(img, [32,32])\n",
    "            dataset.append(img)\n",
    "            labels.append(sign_type)\n",
    "    return np.array(dataset), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' (1).png' ' (10).png' ' (11).png' ' (12).png' ' (13).png' ' (14).png'\n",
      " ' (15).png' ' (16).png' ' (17).png' ' (18).png' ' (19).png' ' (2).png'\n",
      " ' (20).png' ' (21).png' ' (22).png' ' (23).png' ' (24).png' ' (25).png'\n",
      " ' (26).png' ' (27).png' ' (28).png' ' (29).png' ' (3).png' ' (30).png'\n",
      " ' (31).png' ' (32).png' ' (33).png' ' (34).png' ' (35).png' ' (36).png'\n",
      " ' (37).png' ' (38).png' ' (39).png' ' (4).png' ' (40).png' ' (41).png'\n",
      " ' (42).png' ' (43).png' ' (44).png' ' (45).png' ' (46).png' ' (47).png'\n",
      " ' (48).png' ' (49).png' ' (5).png' ' (50).png' ' (51).png' ' (52).png'\n",
      " ' (53).png' ' (54).png' ' (55).png' ' (56).png' ' (57).png' ' (58).png'\n",
      " ' (59).png' ' (6).png' ' (60).png' ' (61).png' ' (62).png' ' (63).png'\n",
      " ' (64).png' ' (65).png' ' (66).png' ' (7).png' ' (8).png' ' (9).png']\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "\n",
    "print(np.array(listdir('./source/Training/data/2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(586, 81)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hog_descriptors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading digits from digits.png ... \n",
      "(586, 32, 32)\n",
      "Shuffle data ... \n",
      "Deskew images ... \n",
      "Defining HoG parameters ...\n",
      "Calculating HoG descriptor for every image ... \n",
      "Spliting data into training (90%) and test set (10%)... \n",
      "Training SVM model ...\n",
      "Saving SVM model ...\n",
      "Evaluating model ... \n",
      "[ 8.  8.  0.  0.  7.  7.  1.  6.  8.  8.  0.  7.  8.  0.  0.  0.  0.  8.\n",
      "  6.  8.  0.  8.  3.  8.  3.  0.  4.  4.  6.  0.  7.  0.  8.  2.  8.  0.\n",
      "  4.  4.  0.  0.  3.  4.  8.  4.  6.  0.  0.  7.  3.  0.  0.  7.  1.  0.\n",
      "  4.  3.  8.  1.  3.]\n",
      "Accuracy: 93.22 %\n",
      "confusion matrix:\n",
      "[[15  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  3  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  6  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  7  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  4  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "def split2d(img, cell_size, flatten=True):\n",
    "    h, w = img.shape[:2]\n",
    "    sx, sy = cell_size\n",
    "    cells = [np.hsplit(row, w//sx) for row in np.vsplit(img, h//sy)]\n",
    "    cells = np.array(cells)\n",
    "    if flatten:\n",
    "        cells = cells.reshape(-1, sy, sx)\n",
    "    return cells\n",
    "\n",
    "def load_digits(fn):\n",
    "    digits_img = cv2.imread(fn, 0)\n",
    "    digits = split2d(digits_img, (SZ, SZ))\n",
    "    labels = np.repeat(np.arange(CLASS_N), len(digits)/CLASS_N)\n",
    "    return digits, labels\n",
    "\n",
    "def deskew(img):\n",
    "    m = cv2.moments(img)\n",
    "    if abs(m['mu02']) < 1e-2:\n",
    "        return img.copy()\n",
    "    skew = m['mu11']/m['mu02']\n",
    "    M = np.float32([[1, skew, -0.5*SZ*skew], [0, 1, 0]])\n",
    "    img = cv2.warpAffine(img, M, (SZ, SZ), flags=cv2.WARP_INVERSE_MAP | cv2.INTER_LINEAR)\n",
    "    return img\n",
    "\n",
    "class StatModel(object):\n",
    "    def load(self, fn):\n",
    "        self.model.load(fn)  # Known bug: https://github.com/opencv/opencv/issues/4969\n",
    "    def save(self, fn):\n",
    "        self.model.save(fn)\n",
    "\n",
    "class SVM(StatModel):\n",
    "    def __init__(self, C = 12.5, gamma = 0.50625):\n",
    "        self.model = cv2.ml.SVM_create()\n",
    "        self.model.setGamma(gamma)\n",
    "        self.model.setC(C)\n",
    "        self.model.setKernel(cv2.ml.SVM_RBF)\n",
    "        self.model.setType(cv2.ml.SVM_C_SVC)\n",
    "\n",
    "    def train(self, samples, responses):\n",
    "        self.model.train(samples, cv2.ml.ROW_SAMPLE, responses)\n",
    "\n",
    "    def predict(self, samples):\n",
    "\n",
    "        return self.model.predict(samples)[1].ravel()\n",
    "\n",
    "\n",
    "def evaluate_model(model, digits, samples, labels):\n",
    "    resp = model.predict(samples)\n",
    "    print(resp)\n",
    "    err = (labels != resp).mean()\n",
    "    print('Accuracy: %.2f %%' % ((1 - err)*100))\n",
    "\n",
    "    confusion = np.zeros((10, 10), np.int32)\n",
    "    for i, j in zip(labels, resp):\n",
    "        confusion[int(i), int(j)] += 1\n",
    "    print('confusion matrix:')\n",
    "    print(confusion)\n",
    "\n",
    "    vis = []\n",
    "    for img, flag in zip(digits, resp == labels):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        if not flag:\n",
    "            img[...,:2] = 0\n",
    "        \n",
    "        vis.append(img)\n",
    "    return mosaic(16, vis)\n",
    "\n",
    "def preprocess_simple(digits):\n",
    "    return np.float32(digits).reshape(-1, SZ*SZ) / 255.0\n",
    "\n",
    "\n",
    "def get_hog() : \n",
    "    winSize = (20,20)\n",
    "    blockSize = (10,10)\n",
    "    blockStride = (5,5)\n",
    "    cellSize = (10,10)\n",
    "    nbins = 9\n",
    "    derivAperture = 1\n",
    "    winSigma = -1.\n",
    "    histogramNormType = 0\n",
    "    L2HysThreshold = 0.2\n",
    "    gammaCorrection = 1\n",
    "    nlevels = 64\n",
    "    signedGradient = True\n",
    "\n",
    "    hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins,derivAperture,winSigma,histogramNormType,L2HysThreshold,gammaCorrection,nlevels, signedGradient)\n",
    "\n",
    "    return hog\n",
    "    affine_flags = cv2.WARP_INVERSE_MAP|cv2.INTER_LINEAR\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    print('Loading digits from digits.png ... ')\n",
    "    # Load data.\n",
    "    #digits, labels = load_digits('digits.png')\n",
    "    digits, labels = load_traffic_dataset()\n",
    "    print(digits.shape)\n",
    "    print('Shuffle data ... ')\n",
    "    # Shuffle data\n",
    "    rand = np.random.RandomState(10)\n",
    "    shuffle = rand.permutation(len(digits))\n",
    "    digits, labels = digits[shuffle], labels[shuffle]\n",
    "    \n",
    "    print('Deskew images ... ')\n",
    "    digits_deskewed = list(map(deskew, digits))\n",
    "    \n",
    "    print('Defining HoG parameters ...')\n",
    "    # HoG feature descriptor\n",
    "    hog = get_hog();\n",
    "\n",
    "    print('Calculating HoG descriptor for every image ... ')\n",
    "    hog_descriptors = []\n",
    "    for img in digits_deskewed:\n",
    "        hog_descriptors.append(hog.compute(img))\n",
    "    hog_descriptors = np.squeeze(hog_descriptors)\n",
    "    \n",
    "    print('Spliting data into training (90%) and test set (10%)... ')\n",
    "    train_n=int(0.9*len(hog_descriptors))\n",
    "    digits_train, digits_test = np.split(digits_deskewed, [train_n])\n",
    "    hog_descriptors_train, hog_descriptors_test = np.split(hog_descriptors, [train_n])\n",
    "    labels_train, labels_test = np.split(labels, [train_n])\n",
    "    \n",
    "    \n",
    "    print('Training SVM model ...')\n",
    "    model = SVM()\n",
    "    model.train(hog_descriptors_train, labels_train)\n",
    "\n",
    "    print('Saving SVM model ...')\n",
    "    model.save('digits_svm.dat')\n",
    "\n",
    "\n",
    "    print('Evaluating model ... ')\n",
    "    vis = evaluate_model(model, digits_test, hog_descriptors_test, labels_test)\n",
    "    cv2.imwrite(\"digits-classification.jpg\",vis)\n",
    "    cv2.imshow(\"Vis\", vis)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLabel(model, data):\n",
    "    cv2.LI\n",
    "    gray = cv2.cvtColor(data, cv2.COLOR_BGR2GRAY)\n",
    "    img = [cv2.resize(gray,(SIZE,SIZE))]\n",
    "    print(np.array(img).shape)\n",
    "    img_deskewed = list(map(deskew, img))\n",
    "    hog = get_hog()\n",
    "    hog_descriptors = np.array([hog.compute(img_deskewed[0])])\n",
    "    hog_descriptors = np.reshape(hog_descriptors, [-1, hog_descriptors.shape[1]])\n",
    "    return int(model.predict(hog_descriptors)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getLabel(model, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = cv2.imread(\"./source/Training/data/4/ (1).png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = cv2.imread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [cv2.resize(a, (32,32))]\n",
    "a_deskewed = list(map(deskew, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(586, 324)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hog_descriptors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = get_hog()\n",
    "hs = np.array([h.compute(a_deskewed[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 324, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hs = np.reshape(hs,[-1,81])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "C:\\ci\\opencv_1512688052760\\work\\modules\\ml\\src\\svm.cpp:2005: error: (-215) samples.cols == var_count && samples.type() == 5 in function cv::ml::SVMImpl::predict\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-4cf7ce2fb0ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-5e731b0e89ec>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, samples)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: C:\\ci\\opencv_1512688052760\\work\\modules\\ml\\src\\svm.cpp:2005: error: (-215) samples.cols == var_count && samples.type() == 5 in function cv::ml::SVMImpl::predict\n"
     ]
    }
   ],
   "source": [
    "model.predict(hs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x234e8e65630>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAScAAAD8CAYAAAA11GIZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x234e72ad390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "cv2.putText(a,'OpenCV',(10,10), font, 4,(255,255,255),2,cv2.LINE_AA)\n",
    "cv2.imshow(\"Test\",a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
